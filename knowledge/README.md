# üìö Knowledge Base Service

A comprehensive document processing and retrieval system built with **Deno**, **ominipg**, and **PostgreSQL**. Extract, chunk, embed, and search through documents from multiple sources with semantic and keyword search capabilities.

## üéØ Overview

The Knowledge Base service provides a complete **Extract ‚Üí Parse ‚Üí Embed ‚Üí Persist ‚Üí Query** pipeline for document processing:

- **üìÑ Multi-format document extraction** (text, web, PDF, videos, etc.)
- **‚úÇÔ∏è Intelligent text chunking** with multiple strategies
- **üß† Vector embeddings** for semantic search
- **üíæ PostgreSQL storage** with optional pgvector support
- **üîç Hybrid search** combining semantic and keyword approaches
- **üóÇÔ∏è Document collections** for organization
- **üåê HTTP API** with Axion Functions integration

## üèóÔ∏è Architecture

```
services/knowledge/
‚îú‚îÄ‚îÄ types.ts                    # TypeScript definitions
‚îú‚îÄ‚îÄ index.ts                    # Main service interface
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îú‚îÄ‚îÄ schema.ts              # PostgreSQL schema
‚îÇ   ‚îî‚îÄ‚îÄ operations.ts          # Database operations
‚îú‚îÄ‚îÄ extractors/                # Document extraction providers
‚îÇ   ‚îú‚îÄ‚îÄ index.ts              # Provider registry
‚îÇ   ‚îú‚îÄ‚îÄ text/index.ts         # Plain text extractor
‚îÇ   ‚îú‚îÄ‚îÄ web/index.ts          # Web scraping extractor
‚îÇ   ‚îú‚îÄ‚îÄ pdf/index.ts          # PDF extractor (stub)
‚îÇ   ‚îú‚îÄ‚îÄ video/index.ts        # Video transcription (stub)
‚îÇ   ‚îú‚îÄ‚îÄ audio/index.ts        # Audio transcription (stub)
‚îÇ   ‚îú‚îÄ‚îÄ doc/index.ts          # Word documents (stub)
‚îÇ   ‚îú‚îÄ‚îÄ csv/index.ts          # CSV parser (stub)
‚îÇ   ‚îî‚îÄ‚îÄ json/index.ts         # JSON parser (stub)
‚îî‚îÄ‚îÄ chunking/index.ts         # Text chunking strategies
```

## üöÄ Quick Start

### Prerequisites

- **Deno 2.0+**
- **PostgreSQL** (optional: with pgvector extension)
- **OpenAI API Key** (for embeddings)

### Installation

```bash
# Clone and navigate to your project
cd your-axion-project

# Set environment variables
export OPENAI_API_KEY="your-openai-key"
export KNOWLEDGE_BASE_DB_URL="postgres://user:pass@localhost/knowledge" # or file://./knowledge.db
```

### Basic Usage

```typescript
import { createKnowledgeBase } from './services/knowledge/index.ts';

// Initialize knowledge base
const kb = await createKnowledgeBase({
  database: {
    url: "file://./knowledge.db"  // or PostgreSQL URL
  },
  embedding: {
    provider: "openai",
    model: "text-embedding-ada-002"
  }
});

// Ingest a document
const result = await kb.process({
  type: 'ingest',
  source: {
    type: 'text',
    content: 'Your document content here...',
    title: 'Sample Document'
  }
});

// Search documents
const searchResult = await kb.process({
  type: 'search',
  query: 'your search query',
  config: {
    searchType: 'hybrid',
    limit: 10
  }
});

console.log(searchResult.results);
```

## üìñ Document Sources

### Text Content
```typescript
{
  type: 'ingest',
  source: {
    type: 'text',
    content: 'Your text content here...',
    title: 'Document Title'
  }
}
```

### Web Pages
```typescript
{
  type: 'ingest',
  source: {
    type: 'url',
    url: 'https://example.com/article',
    headers: { 'Authorization': 'Bearer token' } // optional
  },
  config: {
    provider: 'web',
    options: {
      selector: 'main',           // CSS selector for content
      waitFor: 2000,             // Wait time for page load
      followLinks: false,         // Extract linked pages
      maxDepth: 1                // Link following depth
    }
  }
}
```

### File Uploads
```typescript
{
  type: 'ingest',
  source: {
    type: 'file',
    file: fileBlob,
    fileName: 'document.pdf'
  }
}
```

### Base64 Data
```typescript
{
  type: 'ingest',
  source: {
    type: 'base64',
    data: 'base64-encoded-content',
    mimeType: 'application/pdf',
    fileName: 'document.pdf'
  }
}
```

## ‚úÇÔ∏è Chunking Strategies

### Sentence-based (Default)
Best for articles and general text. Splits at sentence boundaries while respecting chunk size limits.

```typescript
{
  strategy: 'sentences',
  size: 1000,
  overlap: 200
}
```

### Paragraph-based
Ideal for structured documents. Maintains paragraph boundaries.

```typescript
{
  strategy: 'paragraphs',
  size: 1200,
  overlap: 150
}
```

### Fixed-size
For uniform content like code or data.

```typescript
{
  strategy: 'fixed',
  size: 800,
  overlap: 100
}
```

### Semantic
Intelligent splitting based on document structure (headers, sections).

```typescript
{
  strategy: 'semantic',
  size: 1500,
  overlap: 200,
  preserveStructure: true
}
```

## üîç Search Types

### Semantic Search
Uses vector embeddings for meaning-based search:

```typescript
{
  type: 'search',
  query: 'machine learning algorithms',
  config: {
    searchType: 'semantic',
    threshold: 0.7,
    limit: 10
  }
}
```

### Keyword Search
Traditional full-text search:

```typescript
{
  type: 'search',
  query: 'neural networks',
  config: {
    searchType: 'keyword',
    threshold: 0.1,
    limit: 10
  }
}
```

### Hybrid Search (Recommended)
Combines semantic and keyword search with weighted scoring:

```typescript
{
  type: 'search',
  query: 'deep learning',
  config: {
    searchType: 'hybrid',
    threshold: 0.5,
    limit: 10
  }
}
```

## üåê HTTP API

### Ingest Document
```bash
POST /features/knowledge/ingest
Content-Type: application/json

{
  "source": {
    "type": "text",
    "content": "Document content...",
    "title": "My Document"
  },
  "config": {
    "provider": "text",
    "options": {
      "chunkSize": 1000,
      "chunkStrategy": "sentences"
    }
  },
  "collectionId": "optional-collection-id"
}
```

**Response:**
```json
{
  "success": true,
  "documentId": "uuid-here",
  "chunks": 5,
  "processingTime": 1250,
  "message": "Document ingested successfully with 5 chunks"
}
```

### Search Documents
```bash
GET /features/knowledge/search?q=query&type=hybrid&limit=10&threshold=0.5
```

**Response:**
```json
{
  "success": true,
  "results": [
    {
      "documentId": "uuid",
      "chunkId": "chunk-uuid",
      "content": "Relevant text chunk...",
      "score": 0.85,
      "metadata": {},
      "document": {
        "title": "Document Title",
        "documentType": "text",
        "createdAt": "2024-01-01T00:00:00Z"
      }
    }
  ],
  "totalResults": 10,
  "processingTime": 150,
  "query": "search query",
  "searchType": "hybrid"
}
```

## ‚öôÔ∏è Configuration

### Database Configuration
```typescript
const config = {
  database: {
    url: "postgres://user:pass@localhost/kb",  // PostgreSQL
    // OR
    url: "file://./knowledge.db",              // Local file
    syncUrl: "postgres://remote-url",          // Optional sync
    schema: customSchemaArray                  // Optional custom schema
  }
}
```

### Embedding Configuration
```typescript
const config = {
  embedding: {
    provider: "openai",                        // openai | cohere | huggingface
    model: "text-embedding-ada-002",           // Model name
    dimensions: 1536                           // Vector dimensions
  }
}
```

### Chunking Configuration
```typescript
const config = {
  chunking: {
    strategy: "sentences",                     // sentences | paragraphs | fixed | semantic
    size: 1000,                               // Target chunk size
    overlap: 200,                             // Overlap between chunks
    preserveStructure: true,                  // Maintain document structure
    minChunkSize: 100,                        // Minimum chunk size
    maxChunkSize: 2000                        // Maximum chunk size
  }
}
```

## üíæ Database Schema

The service automatically creates these PostgreSQL tables:

### Documents Table
```sql
CREATE TABLE documents (
  id UUID PRIMARY KEY,
  title VARCHAR(500) NOT NULL,
  content TEXT NOT NULL,
  document_type VARCHAR(50) NOT NULL,
  source_type VARCHAR(50) NOT NULL,
  source_url TEXT,
  file_name VARCHAR(255),
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW(),
  status VARCHAR(50) DEFAULT 'processing'
);
```

### Chunks Table
```sql
CREATE TABLE chunks (
  id UUID PRIMARY KEY,
  document_id UUID REFERENCES documents(id),
  content TEXT NOT NULL,
  chunk_index INTEGER NOT NULL,
  metadata JSONB DEFAULT '{}',
  embedding VECTOR(1536),  -- pgvector column
  embedding_model VARCHAR(100),
  created_at TIMESTAMPTZ DEFAULT NOW()
);
```

### Collections & Relationships
```sql
CREATE TABLE collections (
  id UUID PRIMARY KEY,
  name VARCHAR(255) UNIQUE NOT NULL,
  description TEXT,
  metadata JSONB DEFAULT '{}'
);

CREATE TABLE document_collections (
  document_id UUID REFERENCES documents(id),
  collection_id UUID REFERENCES collections(id),
  PRIMARY KEY (document_id, collection_id)
);
```

## üîß Extending the Service

### Adding New Document Extractors

1. **Create extractor implementation:**

```typescript
// services/knowledge/extractors/my-format/index.ts
import type { DocumentExtractor, ExtractorConfig, ExtractionRequest, ExtractionResult } from '../../types.ts';

export class MyFormatExtractor implements DocumentExtractor {
  name = 'my-format' as const;
  supportedTypes = ['my-format'];
  
  constructor(private config: ExtractorConfig) {}
  
  validate(source: any): boolean {
    // Validate if this extractor can handle the source
    return source.type === 'file' && source.file?.type === 'application/my-format';
  }
  
  async extract(request: ExtractionRequest): Promise<ExtractionResult> {
    // Your extraction logic here
    return {
      success: true,
      content: extractedText,
      metadata: { /* document metadata */ },
      processingTime: Date.now() - startTime
    };
  }
}

export function createMyFormatExtractor(config: ExtractorConfig): MyFormatExtractor {
  return new MyFormatExtractor(config);
}
```

2. **Register in the provider registry:**

```typescript
// services/knowledge/extractors/index.ts
import { createMyFormatExtractor } from './my-format/index.ts';

const extractorRegistry: Record<ExtractorName, ExtractorFactory> = {
  // ... existing extractors
  'my-format': createMyFormatExtractor
};
```

3. **Update types:**

```typescript
// services/knowledge/types.ts
export type ExtractorName = 'pdf' | 'web' | 'text' | 'video' | 'doc' | 'audio' | 'csv' | 'json' | 'my-format';
export type DocumentType = 'pdf' | 'doc' | 'docx' | 'txt' | 'md' | 'web' | 'video' | 'audio' | 'csv' | 'json' | 'my-format';
```

### Adding Custom Chunking Strategies

```typescript
// services/knowledge/chunking/index.ts
class CustomChunker implements ChunkingStrategy {
  chunk(content: string, config: ChunkingConfig): TextChunk[] {
    // Your custom chunking logic
    return chunks;
  }
}

const chunkers: Record<ChunkingConfig['strategy'], ChunkingStrategy> = {
  // ... existing chunkers
  'custom': new CustomChunker()
};
```

## üß™ Testing

### Run Built-in Tests
```bash
# Test the HTTP API
deno run --allow-all features/knowledge/index.ts

# Test specific components
deno run --allow-all services/knowledge/extractors/text/index.ts
deno run --allow-all services/knowledge/chunking/index.ts
```

### Example Test Script
```typescript
import { createKnowledgeBase } from './services/knowledge/index.ts';

const kb = await createKnowledgeBase({
  database: { url: ':memory:' }  // In-memory database for testing
});

// Test document ingestion
const result = await kb.process({
  type: 'ingest',
  source: {
    type: 'text',
    content: 'Test document content about artificial intelligence and machine learning.',
    title: 'Test Document'
  }
});

console.log('Ingestion result:', result);

// Test search
const searchResult = await kb.process({
  type: 'search',
  query: 'artificial intelligence',
  config: { searchType: 'hybrid', limit: 5 }
});

console.log('Search results:', searchResult.results);
```

## üõ†Ô∏è Implementation Status

| Component | Status | Notes |
|-----------|--------|-------|
| Text Extractor | ‚úÖ Complete | Handles txt, md, plain text |
| Web Extractor | ‚úÖ Complete | HTML parsing, link following |
| PDF Extractor | üü° Stub | Ready for pdf-parse integration |
| Video Extractor | üü° Stub | Ready for Whisper integration |
| Audio Extractor | üü° Stub | Ready for transcription service |
| Doc Extractor | üü° Stub | Ready for mammoth integration |
| CSV Parser | üü° Stub | Ready for implementation |
| JSON Parser | üü° Stub | Ready for implementation |
| Database Operations | ‚úÖ Complete | Full CRUD with ominipg |
| Vector Search | ‚úÖ Complete | pgvector + JSON fallback |
| Chunking Strategies | ‚úÖ Complete | 4 strategies implemented |
| HTTP API | ‚úÖ Complete | Axion Functions endpoints |

## üéØ Roadmap

### Phase 1: Core Extractors
- [ ] **PDF Extraction**: Integrate `pdf-parse` or `pdfjs-dist`
- [ ] **Word Documents**: Add `mammoth` for .docx parsing
- [ ] **CSV Processing**: Implement CSV parsing with headers
- [ ] **JSON Processing**: Add JSONPath support

### Phase 2: Advanced Features
- [ ] **Audio/Video Transcription**: OpenAI Whisper integration
- [ ] **OCR Support**: Image text extraction
- [ ] **Re-ranking**: Cohere/OpenAI re-ranking for better results
- [ ] **Metadata Extraction**: Enhanced document metadata

### Phase 3: Enterprise Features
- [ ] **Access Control**: Document-level permissions
- [ ] **Audit Logging**: Track all operations
- [ ] **Batch Processing**: Background job queue
- [ ] **Analytics**: Search analytics and insights

## ü§ù Contributing

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Implement** your changes with tests
4. **Commit** your changes (`git commit -m 'Add amazing feature'`)
5. **Push** to the branch (`git push origin feature/amazing-feature`)
6. **Open** a Pull Request

### Development Guidelines

- **Follow TypeScript best practices**
- **Add comprehensive tests** for new features
- **Update documentation** for API changes
- **Use semantic commit messages**
- **Ensure all tests pass** before submitting

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üÜò Support

- **Documentation**: Check this README and inline code comments
- **Issues**: Open a GitHub issue for bugs or feature requests
- **Discussions**: Use GitHub Discussions for questions and ideas

---

## üìö Examples

### Simple Text Ingestion and Search
```typescript
const kb = await createKnowledgeBase({
  database: { url: 'file://./demo.db' }
});

// Ingest a document
await kb.process({
  type: 'ingest',
  source: {
    type: 'text',
    content: 'Machine learning is a subset of artificial intelligence...',
    title: 'ML Basics'
  }
});

// Search for content
const results = await kb.process({
  type: 'search',
  query: 'machine learning',
  config: { searchType: 'hybrid', limit: 5 }
});

console.log(results.results[0].content);
```

### Web Content Ingestion
```typescript
// Scrape and index a web page
await kb.process({
  type: 'ingest',
  source: {
    type: 'url',
    url: 'https://en.wikipedia.org/wiki/Natural_language_processing'
  },
  config: {
    provider: 'web',
    options: {
      selector: '#mw-content-text',
      chunkSize: 1200,
      chunkStrategy: 'semantic'
    }
  }
});
```

### Collection Management
```typescript
// Create a collection
await kb.process({
  type: 'collections',
  action: 'create',
  data: {
    name: 'AI Research Papers',
    description: 'Collection of AI and ML research papers',
    metadata: { topic: 'artificial-intelligence' }
  }
});

// Add document to collection
await kb.process({
  type: 'ingest',
  source: { /* document source */ },
  collectionId: 'collection-uuid'
});
```

Ready to build powerful document processing and search capabilities! üöÄ 